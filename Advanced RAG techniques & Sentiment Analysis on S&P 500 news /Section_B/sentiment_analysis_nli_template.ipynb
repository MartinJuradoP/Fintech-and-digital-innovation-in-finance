{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "635703ee",
   "metadata": {},
   "source": [
    "# Introduction to sentiment analysis with NLI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2040c08f",
   "metadata": {},
   "source": [
    "In this notebook, you will implement a sentiment scoring pipeline using a Natural Language Inference (NLI) model. \n",
    "You will analyze whether news headlines about S&P 500 companies have positive or negative sentiment and explore how this sentiment correlates with market returns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beca6d2d",
   "metadata": {},
   "source": [
    "## Install and Import librairies\n",
    "Install necessary packages and import the required libraries for:\n",
    "- Loading data\n",
    "- Using transformer models\n",
    "- Plotting and visualizing results\n",
    "- Downloading financial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faf52327",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "from tqdm import tqdm\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c7745b",
   "metadata": {},
   "source": [
    "## Load news data\n",
    "Load two datasets:\n",
    "- `df_news.csv`: contains headlines and summaries\n",
    "- `df_metadata.csv`: contains ticker symbols and company sector info\n",
    "\n",
    "We drop duplicate summaries to avoid redundant sentiment scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dc91a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TICKER</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>SUMMARY</th>\n",
       "      <th>PUBLICATION_DATE</th>\n",
       "      <th>PROVIDER</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MMM</td>\n",
       "      <td>2 Dow Jones Stocks with Promising Prospects an...</td>\n",
       "      <td>The Dow Jones (^DJI) is made up of 30 of the m...</td>\n",
       "      <td>2025-05-29 04:33:58+00:00</td>\n",
       "      <td>StockStory</td>\n",
       "      <td>https://finance.yahoo.com/news/2-dow-jones-sto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MMM</td>\n",
       "      <td>3 S&amp;P 500 Stocks Skating on Thin Ice</td>\n",
       "      <td>The S&amp;P 500 (^GSPC) is often seen as a benchma...</td>\n",
       "      <td>2025-05-27 04:34:42+00:00</td>\n",
       "      <td>StockStory</td>\n",
       "      <td>https://finance.yahoo.com/news/3-p-500-stocks-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MMM</td>\n",
       "      <td>3M Rises 15.8% YTD: Should You Buy the Stock N...</td>\n",
       "      <td>MMM is making strides in the aerospace, indust...</td>\n",
       "      <td>2025-05-22 14:08:00+00:00</td>\n",
       "      <td>Zacks</td>\n",
       "      <td>https://finance.yahoo.com/news/3m-rises-15-8-y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MMM</td>\n",
       "      <td>Q1 Earnings Roundup: 3M (NYSE:MMM) And The Res...</td>\n",
       "      <td>Quarterly earnings results are a good time to ...</td>\n",
       "      <td>2025-05-22 03:31:21+00:00</td>\n",
       "      <td>StockStory</td>\n",
       "      <td>https://finance.yahoo.com/news/q1-earnings-rou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MMM</td>\n",
       "      <td>3 Cash-Producing Stocks with Questionable Fund...</td>\n",
       "      <td>While strong cash flow is a key indicator of s...</td>\n",
       "      <td>2025-05-19 04:41:32+00:00</td>\n",
       "      <td>StockStory</td>\n",
       "      <td>https://finance.yahoo.com/news/3-cash-producin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4866</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>2 Dividend Stocks to Buy With $500 and Hold Fo...</td>\n",
       "      <td>Zoetis is a leading animal health company with...</td>\n",
       "      <td>2025-05-23 10:30:00+00:00</td>\n",
       "      <td>Motley Fool</td>\n",
       "      <td>https://www.fool.com/investing/2025/05/23/2-di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4867</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>Zoetis (NYSE:ZTS) Declares US$0.50 Dividend Pe...</td>\n",
       "      <td>Zoetis (NYSE:ZTS) recently affirmed a dividend...</td>\n",
       "      <td>2025-05-22 17:49:43+00:00</td>\n",
       "      <td>Simply Wall St.</td>\n",
       "      <td>https://finance.yahoo.com/news/zoetis-nyse-zts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4868</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>Jim Cramer on Zoetis (ZTS): “It Does Seem to B...</td>\n",
       "      <td>We recently published a list of Jim Cramer Tal...</td>\n",
       "      <td>2025-05-21 18:14:38+00:00</td>\n",
       "      <td>Insider Monkey</td>\n",
       "      <td>https://finance.yahoo.com/news/jim-cramer-zoet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4869</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>Zoetis (ZTS) Upgraded to Buy: Here's Why</td>\n",
       "      <td>Zoetis (ZTS) might move higher on growing opti...</td>\n",
       "      <td>2025-05-21 16:00:08+00:00</td>\n",
       "      <td>Zacks</td>\n",
       "      <td>https://finance.yahoo.com/news/zoetis-zts-upgr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4870</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>ZTS Q1 Earnings Call: Guidance Raised as Platf...</td>\n",
       "      <td>Animal health company Zoetis (NYSE:ZTS) report...</td>\n",
       "      <td>2025-05-19 12:58:02+00:00</td>\n",
       "      <td>StockStory</td>\n",
       "      <td>https://finance.yahoo.com/news/zts-q1-earnings...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3976 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     TICKER                                              TITLE  \\\n",
       "0       MMM  2 Dow Jones Stocks with Promising Prospects an...   \n",
       "1       MMM               3 S&P 500 Stocks Skating on Thin Ice   \n",
       "2       MMM  3M Rises 15.8% YTD: Should You Buy the Stock N...   \n",
       "3       MMM  Q1 Earnings Roundup: 3M (NYSE:MMM) And The Res...   \n",
       "4       MMM  3 Cash-Producing Stocks with Questionable Fund...   \n",
       "...     ...                                                ...   \n",
       "4866    ZTS  2 Dividend Stocks to Buy With $500 and Hold Fo...   \n",
       "4867    ZTS  Zoetis (NYSE:ZTS) Declares US$0.50 Dividend Pe...   \n",
       "4868    ZTS  Jim Cramer on Zoetis (ZTS): “It Does Seem to B...   \n",
       "4869    ZTS           Zoetis (ZTS) Upgraded to Buy: Here's Why   \n",
       "4870    ZTS  ZTS Q1 Earnings Call: Guidance Raised as Platf...   \n",
       "\n",
       "                                                SUMMARY  \\\n",
       "0     The Dow Jones (^DJI) is made up of 30 of the m...   \n",
       "1     The S&P 500 (^GSPC) is often seen as a benchma...   \n",
       "2     MMM is making strides in the aerospace, indust...   \n",
       "3     Quarterly earnings results are a good time to ...   \n",
       "4     While strong cash flow is a key indicator of s...   \n",
       "...                                                 ...   \n",
       "4866  Zoetis is a leading animal health company with...   \n",
       "4867  Zoetis (NYSE:ZTS) recently affirmed a dividend...   \n",
       "4868  We recently published a list of Jim Cramer Tal...   \n",
       "4869  Zoetis (ZTS) might move higher on growing opti...   \n",
       "4870  Animal health company Zoetis (NYSE:ZTS) report...   \n",
       "\n",
       "               PUBLICATION_DATE         PROVIDER  \\\n",
       "0     2025-05-29 04:33:58+00:00       StockStory   \n",
       "1     2025-05-27 04:34:42+00:00       StockStory   \n",
       "2     2025-05-22 14:08:00+00:00            Zacks   \n",
       "3     2025-05-22 03:31:21+00:00       StockStory   \n",
       "4     2025-05-19 04:41:32+00:00       StockStory   \n",
       "...                         ...              ...   \n",
       "4866  2025-05-23 10:30:00+00:00      Motley Fool   \n",
       "4867  2025-05-22 17:49:43+00:00  Simply Wall St.   \n",
       "4868  2025-05-21 18:14:38+00:00   Insider Monkey   \n",
       "4869  2025-05-21 16:00:08+00:00            Zacks   \n",
       "4870  2025-05-19 12:58:02+00:00       StockStory   \n",
       "\n",
       "                                                    URL  \n",
       "0     https://finance.yahoo.com/news/2-dow-jones-sto...  \n",
       "1     https://finance.yahoo.com/news/3-p-500-stocks-...  \n",
       "2     https://finance.yahoo.com/news/3m-rises-15-8-y...  \n",
       "3     https://finance.yahoo.com/news/q1-earnings-rou...  \n",
       "4     https://finance.yahoo.com/news/3-cash-producin...  \n",
       "...                                                 ...  \n",
       "4866  https://www.fool.com/investing/2025/05/23/2-di...  \n",
       "4867  https://finance.yahoo.com/news/zoetis-nyse-zts...  \n",
       "4868  https://finance.yahoo.com/news/jim-cramer-zoet...  \n",
       "4869  https://finance.yahoo.com/news/zoetis-zts-upgr...  \n",
       "4870  https://finance.yahoo.com/news/zts-q1-earnings...  \n",
       "\n",
       "[3976 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_news = pd.read_csv('./data/df_news.csv')\n",
    "df_news.drop_duplicates('SUMMARY', inplace=True)\n",
    "display(df_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dfa76f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TICKER</th>\n",
       "      <th>COMPANY_NAME</th>\n",
       "      <th>SECTOR</th>\n",
       "      <th>INDUSTRY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MMM</td>\n",
       "      <td>3M Company</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Conglomerates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AOS</td>\n",
       "      <td>A. O. Smith Corporation</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Specialty Industrial Machinery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABT</td>\n",
       "      <td>Abbott Laboratories</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>Medical Devices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBV</td>\n",
       "      <td>AbbVie Inc.</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>Drug Manufacturers - General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACN</td>\n",
       "      <td>Accenture plc</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Information Technology Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>XEL</td>\n",
       "      <td>Xcel Energy Inc.</td>\n",
       "      <td>Utilities</td>\n",
       "      <td>Utilities - Regulated Electric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>XYL</td>\n",
       "      <td>Xylem Inc.</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Specialty Industrial Machinery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>YUM</td>\n",
       "      <td>Yum! Brands, Inc.</td>\n",
       "      <td>Consumer Cyclical</td>\n",
       "      <td>Restaurants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>ZBH</td>\n",
       "      <td>Zimmer Biomet Holdings, Inc.</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>Medical Devices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>Zoetis Inc.</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>Drug Manufacturers - Specialty &amp; Generic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>490 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    TICKER                  COMPANY_NAME             SECTOR  \\\n",
       "0      MMM                    3M Company        Industrials   \n",
       "1      AOS       A. O. Smith Corporation        Industrials   \n",
       "2      ABT           Abbott Laboratories         Healthcare   \n",
       "3     ABBV                   AbbVie Inc.         Healthcare   \n",
       "4      ACN                 Accenture plc         Technology   \n",
       "..     ...                           ...                ...   \n",
       "485    XEL              Xcel Energy Inc.          Utilities   \n",
       "486    XYL                    Xylem Inc.        Industrials   \n",
       "487    YUM             Yum! Brands, Inc.  Consumer Cyclical   \n",
       "488    ZBH  Zimmer Biomet Holdings, Inc.         Healthcare   \n",
       "489    ZTS                   Zoetis Inc.         Healthcare   \n",
       "\n",
       "                                     INDUSTRY  \n",
       "0                               Conglomerates  \n",
       "1              Specialty Industrial Machinery  \n",
       "2                             Medical Devices  \n",
       "3                Drug Manufacturers - General  \n",
       "4             Information Technology Services  \n",
       "..                                        ...  \n",
       "485            Utilities - Regulated Electric  \n",
       "486            Specialty Industrial Machinery  \n",
       "487                               Restaurants  \n",
       "488                           Medical Devices  \n",
       "489  Drug Manufacturers - Specialty & Generic  \n",
       "\n",
       "[490 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_meta = pd.read_csv('./data/df_metadata.csv')\n",
    "display(df_meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3daf8233",
   "metadata": {},
   "source": [
    "## Sentiment Analysis with NLI\n",
    "\n",
    "In this section, you will apply a CrossEncoder NLI model (`cross-encoder/nli-deberta-v3-base`) to estimate sentiment from news headlines.\n",
    "\n",
    "👉 **Instructions**:\n",
    "\n",
    "1. Use a CrossEncoder NLI model to compute how much a news headline implies a **positive** or **negative** sentiment.\n",
    "2. For each news title, compute the probability of it being **positive** and **negative**, and store them in `POSITIVE_PROB` and `NEGATIVE_PROB`.\n",
    "3. Derive a final sentiment score by subtracting: `SENTIMENT = POSITIVE_PROB - NEGATIVE_PROB`.\n",
    "\n",
    "✅ This score will serve as your sentiment signal, ranging from negative to positive.\n",
    "\n",
    "> ℹ️ You are free to decide how to structure the input pairs and how to apply the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "952f5670",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: Overall, this news is pos...: 100%|████████████████████████████████████████████████████████████████████████████| 125/125 [03:27<00:00,  1.66s/it]\n",
      "Scoring: Overall, this news is neg...: 100%|████████████████████████████████████████████████████████████████████████████| 125/125 [03:27<00:00,  1.66s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>POSITIVE_PROB</th>\n",
       "      <th>NEGATIVE_PROB</th>\n",
       "      <th>SENTIMENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 Dow Jones Stocks with Promising Prospects an...</td>\n",
       "      <td>0.002061</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>0.001597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3 S&amp;P 500 Stocks Skating on Thin Ice</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>-0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3M Rises 15.8% YTD: Should You Buy the Stock N...</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q1 Earnings Roundup: 3M (NYSE:MMM) And The Res...</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3 Cash-Producing Stocks with Questionable Fund...</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>-0.000194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Here's Why You Should Retain 3M Stock in Your ...</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3M Co: A company with a sound balance sheet, a...</td>\n",
       "      <td>0.000582</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.000447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Rogers, Enviri, 3M, Gates Industrial Corporati...</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3 \"Top Picks\" From Wall Street That Are Magnif...</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3M vs. Honeywell: Which Industrial Conglomerat...</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               TITLE  POSITIVE_PROB  \\\n",
       "0  2 Dow Jones Stocks with Promising Prospects an...       0.002061   \n",
       "1               3 S&P 500 Stocks Skating on Thin Ice       0.000222   \n",
       "2  3M Rises 15.8% YTD: Should You Buy the Stock N...       0.000322   \n",
       "3  Q1 Earnings Roundup: 3M (NYSE:MMM) And The Res...       0.000094   \n",
       "4  3 Cash-Producing Stocks with Questionable Fund...       0.000119   \n",
       "5  Here's Why You Should Retain 3M Stock in Your ...       0.000185   \n",
       "6  3M Co: A company with a sound balance sheet, a...       0.000582   \n",
       "7  Rogers, Enviri, 3M, Gates Industrial Corporati...       0.000360   \n",
       "8  3 \"Top Picks\" From Wall Street That Are Magnif...       0.000328   \n",
       "9  3M vs. Honeywell: Which Industrial Conglomerat...       0.000109   \n",
       "\n",
       "   NEGATIVE_PROB  SENTIMENT  \n",
       "0       0.000463   0.001597  \n",
       "1       0.000234  -0.000012  \n",
       "2       0.000047   0.000275  \n",
       "3       0.000047   0.000046  \n",
       "4       0.000313  -0.000194  \n",
       "5       0.000067   0.000118  \n",
       "6       0.000135   0.000447  \n",
       "7       0.000082   0.000278  \n",
       "8       0.000033   0.000295  \n",
       "9       0.000040   0.000069  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CODE HERE\n",
    "# Use as many coding cells as you need\n",
    "\n",
    "MODEL_NAME = \"cross-encoder/nli-deberta-v3-base\"\n",
    "\n",
    "# Device and model/tokenizer loading\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME).to(device).eval()\n",
    "\n",
    "# Identify entailment index\n",
    "id2label = (\n",
    "    {int(k): v for k, v in model.config.id2label.items()}\n",
    "    if hasattr(model.config, \"id2label\")\n",
    "    else {0: \"contradiction\", 1: \"neutral\", 2: \"entailment\"}\n",
    ")\n",
    "entail_idx = [i for i, name in id2label.items() if \"entail\" in name.lower()]\n",
    "assert len(entail_idx) == 1, f\"No unique entailment label found in id2label={id2label}\"\n",
    "ENTAIL_IDX = entail_idx[0]\n",
    "\n",
    "# Hypotheses\n",
    "H_POS = \"Overall, this news is positive for the company.\"\n",
    "H_NEG = \"Overall, this news is negative for the company.\"\n",
    "\n",
    "# Batched inference helper with tqdm\n",
    "@torch.no_grad()\n",
    "def nli_entailment_prob(premises, hypothesis, batch_size=32, max_length=256):\n",
    "    probs = []\n",
    "    for i in tqdm(range(0, len(premises), batch_size), desc=f\"Scoring: {hypothesis[:25]}...\"):\n",
    "        batch_prem = premises[i:i + batch_size]\n",
    "        enc = tokenizer(\n",
    "            batch_prem,\n",
    "            [hypothesis] * len(batch_prem),\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "            padding=True,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(device)\n",
    "\n",
    "        logits = model(**enc).logits\n",
    "        softmax = torch.nn.functional.softmax(logits, dim=-1)\n",
    "        probs.extend(softmax[:, ENTAIL_IDX].detach().cpu().tolist())\n",
    "    return probs\n",
    "\n",
    "# Prepare titles\n",
    "titles = df_news[\"TITLE\"].fillna(\"\").astype(str).tolist()\n",
    "\n",
    "# Compute POS/NEG probabilities\n",
    "pos_probs = nli_entailment_prob(titles, H_POS, batch_size=32, max_length=256)\n",
    "neg_probs = nli_entailment_prob(titles, H_NEG, batch_size=32, max_length=256)\n",
    "\n",
    "# Add columns to DataFrame\n",
    "df_news[\"POSITIVE_PROB\"] = pos_probs\n",
    "df_news[\"NEGATIVE_PROB\"] = neg_probs\n",
    "df_news[\"SENTIMENT\"] = df_news[\"POSITIVE_PROB\"] - df_news[\"NEGATIVE_PROB\"]\n",
    "\n",
    "# Display a preview nicely in notebook\n",
    "display(df_news[[\"TITLE\", \"POSITIVE_PROB\", \"NEGATIVE_PROB\", \"SENTIMENT\"]].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0c6c11",
   "metadata": {},
   "source": [
    "## Compare Sentiment with Returns\n",
    "\n",
    "In this section, you'll explore how daily news sentiment aligns with market behavior.\n",
    "\n",
    "👉 **Instructions**:\n",
    "\n",
    "1. Group the news data by **publication date** and compute the **average sentiment per day**.\n",
    "2. Download **daily stock prices** for the relevant tickers using `yfinance`.\n",
    "3. Compute **daily returns** and use their average as a proxy for the market (e.g., S\\&P 500).\n",
    "4. Visualize both **daily sentiment** and **daily returns** over time using line plots.\n",
    "5. Create a **dual y-axis chart** to compare trends more effectively.\n",
    "\n",
    "✅ This section helps you assess whether changes in sentiment coincide with market movements.\n",
    "\n",
    "> ℹ️ Focus on trend relationships, not just visual similarity—this is an opportunity to start thinking about predictive signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc0f18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE HERE\n",
    "# Use as many coding cells as you need\n",
    "# 1) Convert publication date to datetime and group by day\n",
    "# ========================\n",
    "# 1) Daily sentiment (news)\n",
    "# ========================\n",
    "# Goal: aggregate a single DAILY_SENTIMENT per calendar day from news\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"yfinance\")\n",
    "\n",
    "# 1) Daily sentiment from news -------------------------------------------------\n",
    "df_news[\"DATE\"] = (\n",
    "    pd.to_datetime(df_news[\"PUBLICATION_DATE\"], utc=True, errors=\"coerce\")\n",
    "      .dt.tz_convert(None)\n",
    "      .dt.normalize()\n",
    ")\n",
    "\n",
    "df_sentiment = (\n",
    "    df_news.groupby(\"DATE\", as_index=False)[\"SENTIMENT\"]\n",
    "           .mean()\n",
    "           .rename(columns={\"SENTIMENT\": \"DAILY_SENTIMENT\"})\n",
    ")\n",
    "\n",
    "# 2) Download prices for relevant tickers (robust) ----------------------------\n",
    "tickers = sorted(set(df_news[\"TICKER\"].dropna().astype(str)))\n",
    "if len(tickers) == 0:\n",
    "    raise ValueError(\"No tickers found in df_news['TICKER'].\")\n",
    "\n",
    "start_date = (df_sentiment[\"DATE\"].min() - pd.Timedelta(days=3)).strftime(\"%Y-%m-%d\")\n",
    "end_date   = (df_sentiment[\"DATE\"].max() + pd.Timedelta(days=3)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "def chunks(seq, size):\n",
    "    for i in range(0, len(seq), size):\n",
    "        yield seq[i:i+size]\n",
    "\n",
    "def exponential_backoff_sleep(attempt, base=1.5, jitter=0.4):\n",
    "    # sleep ~ base^attempt plus jitter\n",
    "    delay = (base ** attempt) + random.uniform(0, jitter)\n",
    "    time.sleep(delay)\n",
    "\n",
    "def download_prices_chunked(tickers_list, start, end, chunk_size=50, retries=3):\n",
    "    \"\"\"\n",
    "    Downloads prices in small chunks (sequential) and retries missing tickers individually.\n",
    "    Returns:\n",
    "      combined: DataFrame with MultiIndex columns (ticker, field)\n",
    "      failed:   set of tickers that failed after all retries\n",
    "    \"\"\"\n",
    "    per_ticker = {}\n",
    "\n",
    "    # 2a) Chunked bulk downloads (sequential, threads=False)\n",
    "    for chunk in chunks(tickers_list, chunk_size):\n",
    "        try:\n",
    "            df = yf.download(\n",
    "                chunk, start=start, end=end,\n",
    "                auto_adjust=False, group_by=\"ticker\",\n",
    "                threads=False, progress=False\n",
    "            )\n",
    "        except Exception as e:\n",
    "            df = pd.DataFrame()\n",
    "\n",
    "        if df.empty:\n",
    "            continue\n",
    "\n",
    "        if isinstance(df.columns, pd.MultiIndex):\n",
    "            present = set(df.columns.get_level_values(0))\n",
    "            for t in chunk:\n",
    "                if t in present:\n",
    "                    per_ticker[t] = df[t].copy()\n",
    "        else:\n",
    "            # single-ticker case\n",
    "            t0 = chunk[0]\n",
    "            per_ticker[t0] = df.copy()\n",
    "\n",
    "    # Determine missing after chunked step\n",
    "    missing = [t for t in tickers_list if t not in per_ticker]\n",
    "\n",
    "    # 2b) Retry missing tickers individually with backoff\n",
    "    for t in missing:\n",
    "        ok = False\n",
    "        for k in range(retries):\n",
    "            try:\n",
    "                df = yf.download(\n",
    "                    t, start=start, end=end,\n",
    "                    auto_adjust=False, group_by=\"ticker\",\n",
    "                    threads=False, progress=False\n",
    "                )\n",
    "                if not df.empty:\n",
    "                    per_ticker[t] = df.copy()\n",
    "                    ok = True\n",
    "                    break\n",
    "            except Exception:\n",
    "                pass\n",
    "            exponential_backoff_sleep(k)\n",
    "        if not ok:\n",
    "            print(f\"[yfinance] Failed after retries: {t}\")\n",
    "\n",
    "    if not per_ticker:\n",
    "        return pd.DataFrame(), set(tickers_list)\n",
    "\n",
    "    combined = pd.concat(per_ticker, axis=1)  # MultiIndex (ticker, field)\n",
    "    failed = set(tickers_list) - set(per_ticker.keys())\n",
    "    return combined, failed\n",
    "\n",
    "prices, failed_tickers = download_prices_chunked(\n",
    "    tickers, start_date, end_date, chunk_size=40, retries=3\n",
    ")\n",
    "\n",
    "if prices.empty:\n",
    "    raise ValueError(\"No price data returned by yfinance for the requested range.\")\n",
    "\n",
    "if failed_tickers:\n",
    "    print(f\"[info] Skipped tickers due to download failures: {sorted(failed_tickers)}\")\n",
    "\n",
    "# 3) Build Adj Close matrix ----------------------------------------------------\n",
    "def get_adj_close_matrix(df_yf, tickers_list):\n",
    "    if not isinstance(df_yf.columns, pd.MultiIndex):\n",
    "        if \"Adj Close\" in df_yf.columns:\n",
    "            adj = df_yf[[\"Adj Close\"]].copy()\n",
    "        else:\n",
    "            adj = df_yf[[\"Close\"]].copy()\n",
    "        name = tickers_list[0] if len(tickers_list) == 1 else \"ASSET\"\n",
    "        adj.columns = [name]\n",
    "        return adj\n",
    "\n",
    "    frames = []\n",
    "    for t in tickers_list:\n",
    "        if t in df_yf.columns.get_level_values(0):\n",
    "            if (t, \"Adj Close\") in df_yf.columns:\n",
    "                s = df_yf[(t, \"Adj Close\")].rename(t)\n",
    "            elif (t, \"Close\") in df_yf.columns:\n",
    "                s = df_yf[(t, \"Close\")].rename(t)\n",
    "            else:\n",
    "                continue\n",
    "            frames.append(s)\n",
    "    if not frames:\n",
    "        raise ValueError(\"Could not find 'Adj Close' or 'Close' for any ticker.\")\n",
    "    return pd.concat(frames, axis=1)\n",
    "\n",
    "valid_tickers = [t for t in tickers if t not in failed_tickers]\n",
    "adj_close = get_adj_close_matrix(prices, valid_tickers).dropna(axis=1, how=\"all\")\n",
    "\n",
    "# 4) Returns per ticker & equal-weighted market proxy -------------------------\n",
    "ret = adj_close.pct_change(fill_method=None)  # explicit to avoid FutureWarning\n",
    "market_return = ret.mean(axis=1, skipna=True).rename(\"RETURN\")\n",
    "\n",
    "# 5) Align dates and merge with sentiment -------------------------------------\n",
    "mkt = (\n",
    "    market_return\n",
    "    .to_frame()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"index\": \"DATE\", \"Date\": \"DATE\"})\n",
    ")\n",
    "mkt[\"DATE\"] = pd.to_datetime(mkt[\"DATE\"]).dt.normalize()\n",
    "\n",
    "df_compare = (\n",
    "    pd.merge(df_sentiment, mkt, on=\"DATE\", how=\"inner\")\n",
    "      .sort_values(\"DATE\")\n",
    "      .dropna(subset=[\"RETURN\"])\n",
    ")\n",
    "\n",
    "# 6) Plot: dual y-axis (sentiment vs equal-weighted return) -------------------\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "ax1.set_xlabel(\"Date\", fontsize=12)\n",
    "ax1.set_ylabel(\"Average Daily Sentiment (NLI-based)\", color=\"tab:blue\", fontsize=12)\n",
    "line1, = ax1.plot(\n",
    "    df_compare[\"DATE\"],\n",
    "    df_compare[\"DAILY_SENTIMENT\"],\n",
    "    color=\"tab:blue\",\n",
    "    label=\"Daily Sentiment\"\n",
    ")\n",
    "ax1.tick_params(axis=\"y\", labelcolor=\"tab:blue\")\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel(\"Equal-Weighted Daily Return (across tickers)\", color=\"tab:green\", fontsize=12)\n",
    "line2, = ax2.plot(\n",
    "    df_compare[\"DATE\"],\n",
    "    df_compare[\"RETURN\"],\n",
    "    color=\"tab:green\",\n",
    "    linestyle=\"--\",\n",
    "    label=\"Daily Return (EW)\"\n",
    ")\n",
    "ax2.tick_params(axis=\"y\", labelcolor=\"tab:green\")\n",
    "\n",
    "fig.suptitle(\"Daily News Sentiment vs. Equal-Weighted Market Returns\", fontsize=14, fontweight=\"bold\")\n",
    "fig.text(\n",
    "    0.5, -0.05,\n",
    "    \"This chart compares average daily news sentiment (left axis) with equal-weighted daily returns\\n\"\n",
    "    \"of tickers mentioned in the news (right axis). Use it to assess whether sentiment shifts align with market moves.\",\n",
    "    ha=\"center\", va=\"top\", fontsize=10\n",
    ")\n",
    "\n",
    "lines = [line1, line2]\n",
    "labels = [l.get_label() for l in lines]\n",
    "ax1.legend(lines, labels, loc=\"upper left\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 7) Inspect merged data -------------------------------------------------------\n",
    "display(df_compare.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b74e233",
   "metadata": {},
   "source": [
    "## Compare Daily Portfolio Value Against Daily Average Sentiment\n",
    "\n",
    "In this section, you will simulate a simple market portfolio and explore how its performance aligns with daily sentiment scores.\n",
    "\n",
    "👉 **Instructions**:\n",
    "\n",
    "1. Simulate a **market portfolio** by computing the cumulative return of the average daily return across all tickers.\n",
    "2. Start the portfolio with an **initial value of 1.0** and track its value over time.\n",
    "3. Plot the **daily average sentiment** and the **portfolio value** using a dual-axis line chart.\n",
    "\n",
    "✅ This visualization lets you explore whether market sentiment leads or lags behind portfolio movements.\n",
    "\n",
    "> ℹ️ Think about how this setup could inform a basic trading strategy—or whether sentiment could serve as a timing signal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b275cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE HERE\n",
    "# Use as many coding cells as you need\n",
    "# 1) Build a simple “market portfolio” from equal-weighted daily returns\n",
    "#    Start at 1.0 and compound forward: V_t = V_{t-1} * (1 + r_t)\n",
    "portfolio = (\n",
    "    (1.0 + market_return.fillna(0.0)).cumprod()\n",
    "    .rename(\"PORTFOLIO_VALUE\")\n",
    ")\n",
    "\n",
    "# 2) Align dates and merge with daily sentiment\n",
    "port = (\n",
    "    portfolio.to_frame()\n",
    "             .reset_index()\n",
    "             .rename(columns={\"index\":\"DATE\", \"Date\":\"DATE\"})\n",
    ")\n",
    "port[\"DATE\"] = pd.to_datetime(port[\"DATE\"]).dt.normalize()\n",
    "\n",
    "df_port_compare = (\n",
    "    pd.merge(df_sentiment, port, on=\"DATE\", how=\"inner\")\n",
    "      .sort_values(\"DATE\")\n",
    ")\n",
    "\n",
    "# 3) Plot: dual y-axis (sentiment vs portfolio value)\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Left axis: Daily average sentiment (NLI-based)\n",
    "ax1.set_xlabel(\"Date\", fontsize=12)\n",
    "ax1.set_ylabel(\"Average Daily Sentiment (NLI-based)\", color=\"tab:blue\", fontsize=12)\n",
    "l1, = ax1.plot(\n",
    "    df_port_compare[\"DATE\"],\n",
    "    df_port_compare[\"DAILY_SENTIMENT\"],\n",
    "    color=\"tab:blue\",\n",
    "    label=\"Daily Sentiment\"\n",
    ")\n",
    "ax1.tick_params(axis=\"y\", labelcolor=\"tab:blue\")\n",
    "\n",
    "# Right axis: Portfolio value (cum. return of equal-weighted daily returns)\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel(\"Simulated Portfolio Value (EW cumulative)\", color=\"tab:green\", fontsize=12)\n",
    "l2, = ax2.plot(\n",
    "    df_port_compare[\"DATE\"],\n",
    "    df_port_compare[\"PORTFOLIO_VALUE\"],\n",
    "    color=\"tab:green\",\n",
    "    linestyle=\"--\",\n",
    "    label=\"Portfolio Value (EW)\"\n",
    ")\n",
    "ax2.tick_params(axis=\"y\", labelcolor=\"tab:green\")\n",
    "\n",
    "# Title + explanatory note\n",
    "fig.suptitle(\"Daily Sentiment vs. Simulated Equal-Weighted Portfolio Value\", fontsize=14, fontweight=\"bold\")\n",
    "fig.text(\n",
    "    0.5, -0.05,\n",
    "    \"Portfolio = cumulative product of (1 + equal-weighted daily returns) starting at 1.0.\\n\"\n",
    "    \"This dual-axis view helps inspect whether sentiment shifts lead or lag portfolio movements.\",\n",
    "    ha=\"center\", va=\"top\", fontsize=10\n",
    ")\n",
    "\n",
    "# Combined legend\n",
    "lines = [l1, l2]\n",
    "labels = [l.get_label() for l in lines]\n",
    "ax1.legend(lines, labels, loc=\"upper left\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4) Preview the merged frame\n",
    "display(df_port_compare.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5a2603",
   "metadata": {},
   "source": [
    "## Compute Sector-Level Sentiment and Returns\n",
    "\n",
    "In this section, you’ll analyze how sector-level news sentiment compares to market performance for May. You’ll also measure whether sentiment correlates with returns.\n",
    "\n",
    "👉 **Instructions**:\n",
    "\n",
    "1. Group companies by **sector** using the metadata.\n",
    "2. For each sector:\n",
    "\n",
    "   * Compute **monthly average sentiment** (Feb to May).\n",
    "   * (Optional) Count the number of headlines per month.\n",
    "3. Compute **monthly stock returns** from price data and extract **May returns**.\n",
    "4. Build a comparison table with:\n",
    "\n",
    "   * `SECTOR`\n",
    "   * `SENTIMENT` (May sentiment)\n",
    "   * `RETURN` (May return)\n",
    "5. Compute and print the **correlation** between May sentiment and May returns.\n",
    "\n",
    "✅ This step helps evaluate whether optimistic news coverage for a sector is associated with better performance.\n",
    "\n",
    "> 💡 Once your analysis is complete, consider:\n",
    ">\n",
    "> * Which sectors *looked* good in the news but didn’t perform?\n",
    "> * Which sectors performed well despite neutral/negative sentiment?\n",
    "> * Would you invest based on sentiment alone? Why or why not?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a6d97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE HERE\n",
    "# Use as many coding cells as you need\n",
    "# --- Compute Sector-Level Sentiment and Returns (Feb–May, compare May) ---\n",
    "\n",
    "# --- Compute Sector-Level Sentiment and Returns (Feb–May, compare May) ---\n",
    "# Updated to use month-end \"ME\" everywhere (no deprecation warnings)\n",
    "\n",
    "_meta = df_meta.copy()\n",
    "_meta.columns = [c.upper() for c in _meta.columns]\n",
    "\n",
    "# Pick a sector column robustly\n",
    "_sector_col = None\n",
    "for cand in [\"SECTOR\", \"GICS_SECTOR\", \"SECTOR_NAME\", \"SECTOR_NAME_LONG\"]:\n",
    "    if cand in _meta.columns:\n",
    "        _sector_col = cand\n",
    "        break\n",
    "if _sector_col is None:\n",
    "    raise ValueError(\"No sector column found in df_meta. Expected one of: SECTOR, GICS_SECTOR, SECTOR_NAME.\")\n",
    "\n",
    "meta_sector = _meta[[\"TICKER\", _sector_col]].dropna().drop_duplicates()\n",
    "meta_sector = meta_sector.rename(columns={_sector_col: \"SECTOR\"})\n",
    "meta_sector[\"TICKER\"] = meta_sector[\"TICKER\"].astype(str)\n",
    "\n",
    "# 1) Prepare dates in news (ensure we have DATE at day granularity) -----------\n",
    "df_news[\"DATE\"] = (\n",
    "    pd.to_datetime(df_news[\"PUBLICATION_DATE\"], utc=True, errors=\"coerce\")\n",
    "      .dt.tz_convert(None)\n",
    "      .dt.normalize()\n",
    ")\n",
    "\n",
    "# Month-end timestamps to align with monthly returns (use 'ME' explicitly)\n",
    "df_news[\"DATE\"] = (\n",
    "    pd.to_datetime(df_news[\"PUBLICATION_DATE\"], utc=True, errors=\"coerce\")\n",
    "      .dt.tz_convert(None)\n",
    "      .dt.normalize()\n",
    ")\n",
    "\n",
    "# Month-end timestamps to align with monthly returns\n",
    "df_news[\"MONTH\"] = df_news[\"DATE\"].dt.to_period(\"M\").dt.to_timestamp(\"M\")\n",
    "\n",
    "# 2) Monthly returns per ticker (from adj_close) -------------------------------\n",
    "# Use 'ME' for resampling (valid for resample)\n",
    "monthly_prices = adj_close.resample(\"ME\").last()\n",
    "monthly_returns = monthly_prices.pct_change()\n",
    "\n",
    "# Target: most recent MAY available in prices\n",
    "available_mays = monthly_returns.index[monthly_returns.index.month == 5]\n",
    "if len(available_mays) == 0:\n",
    "    raise ValueError(\"No May found in monthly returns index.\")\n",
    "target_may = available_mays.max()\n",
    "target_year = target_may.year\n",
    "\n",
    "# Limit the analysis window to Feb–May of the target year\n",
    "months_window = pd.period_range(f\"{target_year}-02\", f\"{target_year}-05\", freq=\"M\").to_timestamp(\"M\")\n",
    "\n",
    "# 3) Sector-level monthly sentiment (Feb–May) ---------------------------------\n",
    "news_w_sector = (\n",
    "    df_news.merge(meta_sector, on=\"TICKER\", how=\"left\")\n",
    "           .dropna(subset=[\"SECTOR\"])\n",
    ")\n",
    "\n",
    "sector_monthly_sent = (\n",
    "    news_w_sector[news_w_sector[\"MONTH\"].isin(months_window)]\n",
    "      .groupby([\"SECTOR\", \"MONTH\"], as_index=False)\n",
    "      .agg(\n",
    "          SENTIMENT=(\"SENTIMENT\", \"mean\"),\n",
    "          HEADLINES=(\"SENTIMENT\", \"size\")  # optional: count of headlines\n",
    "      )\n",
    ")\n",
    "\n",
    "# Nice pivot for inspection (avg sentiment Feb–May by sector)\n",
    "sent_pivot = (\n",
    "    sector_monthly_sent\n",
    "      .pivot(index=\"SECTOR\", columns=\"MONTH\", values=\"SENTIMENT\")\n",
    "      .sort_index()\n",
    ")\n",
    "sent_pivot.columns = [c.strftime(\"%Y-%m\") for c in sent_pivot.columns]  # pretty month labels\n",
    "\n",
    "# 4) Sector-level MAY returns (equal-weight across tickers in sector) ---------\n",
    "# Map tickers to sectors only for tickers present in prices\n",
    "tickers_in_prices = set(adj_close.columns.astype(str))\n",
    "meta_valid = meta_sector[meta_sector[\"TICKER\"].isin(tickers_in_prices)]\n",
    "\n",
    "# Ticker-level May returns (single row, index=ticker)\n",
    "may_ret_by_ticker = monthly_returns.loc[target_may].dropna()\n",
    "may_ret_by_ticker.index = may_ret_by_ticker.index.astype(str)\n",
    "\n",
    "# Join to sectors\n",
    "may_ret_with_sector = (\n",
    "    pd.DataFrame({\"TICKER\": may_ret_by_ticker.index, \"RETURN\": may_ret_by_ticker.values})\n",
    "      .merge(meta_valid, on=\"TICKER\", how=\"left\")\n",
    "      .dropna(subset=[\"SECTOR\"])\n",
    ")\n",
    "\n",
    "# Sector-level equal-weight return in May\n",
    "sector_may_returns = (\n",
    "    may_ret_with_sector\n",
    "      .groupby(\"SECTOR\", as_index=False)[\"RETURN\"]\n",
    "      .mean()\n",
    ")\n",
    "\n",
    "# 5) Sector-level MAY sentiment ----------------------------------------------\n",
    "sector_may_sent = (\n",
    "    sector_monthly_sent[sector_monthly_sent[\"MONTH\"] == target_may]\n",
    "      .loc[:, [\"SECTOR\", \"SENTIMENT\", \"HEADLINES\"]]\n",
    "      .rename(columns={\"SENTIMENT\": \"SENTIMENT_MAY\", \"HEADLINES\": \"HEADLINES_MAY\"})\n",
    ")\n",
    "\n",
    "# 6) Comparison table: SECTOR, SENTIMENT (May), RETURN (May) ------------------\n",
    "sector_compare = (\n",
    "    sector_may_sent.merge(sector_may_returns, on=\"SECTOR\", how=\"outer\")\n",
    "                   .rename(columns={\"SENTIMENT_MAY\": \"SENTIMENT\", \"RETURN\": \"RETURN\"})\n",
    "                   .sort_values([\"RETURN\", \"SENTIMENT\"], ascending=False)\n",
    "                   .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# 7) Correlation between May sentiment and May returns ------------------------\n",
    "valid = sector_compare.dropna(subset=[\"SENTIMENT\", \"RETURN\"])\n",
    "corr = valid[\"SENTIMENT\"].corr(valid[\"RETURN\"]) if len(valid) >= 2 else np.nan\n",
    "\n",
    "# 8) Display results -----------------------------------------------------------\n",
    "print(f\"Target window: Feb–May {target_year} | Target May: {target_may.date()}\")\n",
    "print(\"\\nMonthly average sentiment by sector (Feb–May):\")\n",
    "display(sent_pivot)\n",
    "\n",
    "print(\"\\nSector comparison for May (sentiment vs return):\")\n",
    "display(sector_compare[[\"SECTOR\", \"SENTIMENT\", \"RETURN\", \"HEADLINES_MAY\"]])\n",
    "\n",
    "print(\n",
    "    f\"\\nCorrelation (Pearson) between May sentiment and May returns: {corr:.4f}\"\n",
    "    if pd.notna(corr) else\n",
    "    \"\\nCorrelation could not be computed (insufficient valid sectors).\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00ef898",
   "metadata": {},
   "source": [
    "### **Question 1.** Which sectors *looked* good in the news? How did they perform?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9b5f97",
   "metadata": {},
   "source": [
    "Sectors that had strong sentiment in the news were **Consumer Cyclical** (highest sentiment: 0.001167), **Technology** (0.000265), and **Industrials** (0.000144).\n",
    "\n",
    "* **Technology** translated that positive news into the **highest return (7.5%)**, showing alignment between sentiment and market performance.\n",
    "* **Industrials** also matched strong sentiment with a **7.4% return**.\n",
    "* **Consumer Cyclical** looked excellent in the news but only delivered a **5.6% return**, suggesting that optimism didn’t fully materialize into market outperformance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec996906",
   "metadata": {},
   "source": [
    "### **Question 2.** Which sectors performed well despite neutral/negative sentiment?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5365837a",
   "metadata": {},
   "source": [
    "Some sectors posted solid returns even though sentiment wasn’t particularly strong:\n",
    "\n",
    "* **Financial Services** had only mild sentiment (0.000069) but achieved a **6.1% return**.\n",
    "* **Utilities** sentiment was very low (0.000164), but the sector returned **3.3%**.\n",
    "* **Energy** sentiment was neutral (0.000121), yet it returned **2.9%**.\n",
    "\n",
    "This suggests that market performance in these sectors was driven by fundamentals or external factors not captured by news sentiment.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4df337",
   "metadata": {},
   "source": [
    "### **Question 3.**  Would you invest based on sentiment alone? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce35f83",
   "metadata": {},
   "source": [
    "No — investing based on sentiment alone would be risky. While **Technology and Industrials** show that positive sentiment can align with strong performance, examples like **Consumer Cyclical** (high sentiment but only moderate returns) and **Healthcare** (neutral sentiment and near-zero return) show that sentiment is not a reliable standalone predictor.\n",
    "Market behavior is influenced by fundamentals, macroeconomic conditions, and investor positioning — sentiment provides context but not the full picture.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e885fca1",
   "metadata": {},
   "source": [
    "### **Question 4.**  How would you go about testing a sentiment analysis strategy in a more robust way?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8125c37",
   "metadata": {},
   "source": [
    "A robust test of a sentiment-driven strategy would involve:\n",
    "\n",
    "1. **Backtesting** across multiple years and market cycles, not just one period, to see if sentiment consistently aligns with returns.\n",
    "2. **Cross-validation by sector** — does sentiment work better in some industries (e.g., Tech) than others (e.g., Defensive sectors)?\n",
    "3. **Alternative sentiment metrics** — compare average daily sentiment, weighted sentiment by volume of headlines, and sentiment momentum (change in sentiment).\n",
    "4. **Portfolio simulation** — build long-short strategies (e.g., long high-sentiment sectors, short low-sentiment sectors) and evaluate risk-adjusted performance (Sharpe ratio, drawdowns).\n",
    "5. **Control for confounding variables** — include macro factors (interest rates, oil prices, earnings announcements) to ensure sentiment adds unique predictive power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc9e922-96a8-45da-81a3-c9fb020d6c42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
